{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import joblib\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from toxic.inference_bert import get_token_ids\n",
    "from toxic.dataset import AUX_COLUMNS, ToxicDataset, collate_examples, SortSampler\n",
    "from toxic.common import ToxicBot\n",
    "from toxic.metric import ToxicMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"../data/cache/\")\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = joblib.load(str(MODEL_PATH / \"bert-base-uncased_tokenizer.jbl\"))\n",
    "model = torch.load(str(MODEL_PATH / \"bert-base-uncased_-1_yuval_220_f0.pth\")).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = partial(\n",
    "    collate_examples,\n",
    "    truncate_len=220,\n",
    "    pad=0,\n",
    "    closing_id=tokenizer.vocab[\"[SEP]\"],\n",
    "    mode=\"both\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pbs.twimg.com/media/DICFy_jWsAE6s6V?format=jpg&name=small)\n",
    "[source](https://twitter.com/jessamyn/status/900867154412699649)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [\n",
    "    \"I am a man\",\n",
    "    \"I am a woman\",\n",
    "    \"I am a lesbian\",\n",
    "    \"I am gay man\",\n",
    "    \"I am dyke\",\n",
    "    \"I am a white man\",\n",
    "    \"I am a gay woman\",\n",
    "    \"I am a white woman\",\n",
    "    \"I am a gay white man\",\n",
    "    \"I am a black man\",\n",
    "    \"I am a gay white man\",\n",
    "    \"I am a gay black man\",\n",
    "    \"I am a black woman\",\n",
    "    \"I am a gay black woman\"\n",
    "]\n",
    "df = pd.DataFrame(dict(comment_text=test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_token_ids(\n",
    "    df, tokenizer, is_bert=True)\n",
    "test_ds = ToxicDataset(df, tokens, labeled=False)\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    results = []\n",
    "    for batch, _ in test_loader:\n",
    "        results.append(model(batch.cuda()))\n",
    "    results = torch.sigmoid(torch.cat(results)) * 100\n",
    "    results.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(results.cpu().numpy(), columns=AUX_COLUMNS)\n",
    "predictions[\"text\"] = df[\"comment_text\"].values\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult',\n",
       "       'threat', 'male', 'female', 'homosexual_gay_or_lesbian', 'christian',\n",
       "       'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness',\n",
       "       'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a man</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a woman</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.82</td>\n",
       "      <td>98.79</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a lesbian</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>97.30</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am gay man</td>\n",
       "      <td>3.24</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0.34</td>\n",
       "      <td>93.88</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am dyke</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am a white man</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.73</td>\n",
       "      <td>98.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am a gay woman</td>\n",
       "      <td>3.74</td>\n",
       "      <td>8.48</td>\n",
       "      <td>78.52</td>\n",
       "      <td>91.64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I am a white woman</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.79</td>\n",
       "      <td>93.79</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.70</td>\n",
       "      <td>98.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I am a gay white man</td>\n",
       "      <td>17.33</td>\n",
       "      <td>24.38</td>\n",
       "      <td>0.91</td>\n",
       "      <td>96.12</td>\n",
       "      <td>1.44</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I am a black man</td>\n",
       "      <td>7.17</td>\n",
       "      <td>16.17</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.53</td>\n",
       "      <td>98.17</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I am a gay white man</td>\n",
       "      <td>30.20</td>\n",
       "      <td>31.88</td>\n",
       "      <td>1.06</td>\n",
       "      <td>65.68</td>\n",
       "      <td>1.24</td>\n",
       "      <td>99.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I am a gay black man</td>\n",
       "      <td>13.94</td>\n",
       "      <td>28.13</td>\n",
       "      <td>1.09</td>\n",
       "      <td>94.20</td>\n",
       "      <td>96.79</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I am a black woman</td>\n",
       "      <td>3.42</td>\n",
       "      <td>7.51</td>\n",
       "      <td>97.90</td>\n",
       "      <td>0.27</td>\n",
       "      <td>97.00</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I am a gay black woman</td>\n",
       "      <td>13.40</td>\n",
       "      <td>19.04</td>\n",
       "      <td>93.14</td>\n",
       "      <td>71.22</td>\n",
       "      <td>92.14</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text  toxic  identity_attack  female  homosexual  black  \\\n",
       "0               I am a man   0.61             0.27    3.37        0.12   0.01   \n",
       "1             I am a woman   0.69             0.82   98.79        0.08   0.16   \n",
       "2           I am a lesbian   6.35             5.11    0.10       97.30   0.07   \n",
       "3             I am gay man   3.24             9.14    0.34       93.88   0.39   \n",
       "4                I am dyke   1.29             0.11    0.02        0.00   0.00   \n",
       "5         I am a white man   1.55             3.80    1.36        0.03   0.73   \n",
       "6         I am a gay woman   3.74             8.48   78.52       91.64   0.10   \n",
       "7       I am a white woman   1.22             4.79   93.79        0.11   0.70   \n",
       "8     I am a gay white man  17.33            24.38    0.91       96.12   1.44   \n",
       "9         I am a black man   7.17            16.17    2.03        1.53  98.17   \n",
       "10    I am a gay white man  30.20            31.88    1.06       65.68   1.24   \n",
       "11    I am a gay black man  13.94            28.13    1.09       94.20  96.79   \n",
       "12      I am a black woman   3.42             7.51   97.90        0.27  97.00   \n",
       "13  I am a gay black woman  13.40            19.04   93.14       71.22  92.14   \n",
       "\n",
       "    white  \n",
       "0    0.03  \n",
       "1    0.03  \n",
       "2    0.02  \n",
       "3    0.05  \n",
       "4    0.00  \n",
       "5   98.58  \n",
       "6    0.23  \n",
       "7   98.87  \n",
       "8   78.75  \n",
       "9    1.03  \n",
       "10  99.23  \n",
       "11   0.68  \n",
       "12   2.15  \n",
       "13   0.83  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[[\"text\", \"target\", \"identity_attack\", \"female\", \"homosexual_gay_or_lesbian\", \"black\", \"white\"]].rename(\n",
    "    columns={\"target\": \"toxic\", \"homosexual_gay_or_lesbian\":\"homosexual\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other random examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [\n",
    "    \"Pretty sad really. Thousands come out to protest Trump who's in another country......and all those NDP and Green members - who were the driving force behind Proportional Representation - couldn't find the time to get out to support their own cause. That said, you can bet that Trudeau has alredy lost a good portion of that NDP/Green vote. The guy's a liar. Period.\",\n",
    "    \"Idiots.\",\n",
    "    \"Then put them in jail until they decide to cooperate.  This is ridiculous....\",\n",
    "    \"\\\"He’s a proven liar. Why would you believe anything he has to say?\\\"\\n\\nExactly.\\nThat\\'s why I do not listen to a word Donnie says.\",\n",
    "    \"Fascinating young woman, impressive work. It reminds me of one of the reasons I love Alaska so much —\\xa0the people Alaska attracts are often just as extraordinary as the landscape itself. Great article, thank you.\",\n",
    "    \"Well, at least the Russians are white, for heaven's sakes.  I'd rather have to live next to a nice white drunk Russian than a black Muslim Kenyan whose children's names are Satanic anagrams.\",\n",
    "    \"Was I posted yesterday, it is interesting to note that under Session's watch only three black people have been appointed in Alabama for the federal courts. This despite the fact that black people make up over 39% of the population of that state. What underlines this reality must be Session's unconscious, if not conscious, attitude towards blacks in general.\"\n",
    "]\n",
    "df = pd.DataFrame(dict(comment_text=test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88, 3, 19, 36, 42, 48, 72]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pretty sad really. Thousands come out to prote...</td>\n",
       "      <td>49.56</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Idiots.</td>\n",
       "      <td>93.84</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then put them in jail until they decide to coo...</td>\n",
       "      <td>65.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"He’s a proven liar. Why would you believe any...</td>\n",
       "      <td>43.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fascinating young woman, impressive work. It r...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>66.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Well, at least the Russians are white, for hea...</td>\n",
       "      <td>86.47</td>\n",
       "      <td>84.04</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>85.57</td>\n",
       "      <td>95.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Was I posted yesterday, it is interesting to n...</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.58</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>98.41</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  identity_attack  \\\n",
       "0  Pretty sad really. Thousands come out to prote...  49.56             0.36   \n",
       "1                                            Idiots.  93.84             1.45   \n",
       "2  Then put them in jail until they decide to coo...  65.76             0.54   \n",
       "3  \"He’s a proven liar. Why would you believe any...  43.15             0.32   \n",
       "4  Fascinating young woman, impressive work. It r...   0.33             0.30   \n",
       "5  Well, at least the Russians are white, for hea...  86.47            84.04   \n",
       "6  Was I posted yesterday, it is interesting to n...  13.69            12.58   \n",
       "\n",
       "   female  homosexual  black  white  \n",
       "0    0.08        0.00   0.00   0.01  \n",
       "1    0.09        0.00   0.00   0.03  \n",
       "2    0.02        0.00   0.00   0.00  \n",
       "3    0.02        0.00   0.00   0.01  \n",
       "4   66.28        0.08   0.08   0.06  \n",
       "5    1.25        0.28  85.57  95.26  \n",
       "6    0.14        0.03  98.41   0.20  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = get_token_ids(\n",
    "    df, tokenizer, is_bert=True)\n",
    "print([len(x) for x in tokens])\n",
    "test_ds = ToxicDataset(df, tokens, labeled=False)\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "with torch.no_grad():\n",
    "    results = []\n",
    "    for batch, _ in test_loader:\n",
    "        results.append(model(batch.cuda()))\n",
    "    results = torch.sigmoid(torch.cat(results)) * 100\n",
    "    results.size()\n",
    "predictions = pd.DataFrame(results.cpu().numpy(), columns=AUX_COLUMNS)\n",
    "predictions[\"text\"] = df[\"comment_text\"].values\n",
    "predictions[[\"text\", \"target\", \"identity_attack\", \"female\", \"homosexual_gay_or_lesbian\", \"black\", \"white\"]].rename(\n",
    "    columns={\"target\": \"toxic\", \"homosexual_gay_or_lesbian\":\"homosexual\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate\n",
    "Make sure the mode is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    32000.0000\n",
      "mean         0.0914\n",
      "std          0.2074\n",
      "min          0.0000\n",
      "25%          0.0000\n",
      "50%          0.0000\n",
      "75%          0.0918\n",
      "max          1.0000\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_valid, tokens_valid = joblib.load(str(MODEL_PATH / \"valid_bert-base-uncased_-1_yuval_f0.jbl\"))\n",
    "idx = np.random.choice(np.arange(df_valid.shape[0]), 32 * 1000)\n",
    "df_valid, tokens_valid = df_valid.iloc[idx].reset_index(drop=True), tokens_valid[idx]\n",
    "valid_ds = ToxicDataset(df_valid, tokens_valid, labeled=True)\n",
    "val_sampler = SortSampler(valid_ds, key=lambda x: len(valid_ds.tokens[x]))\n",
    "df_valid = df_valid.iloc[list(iter(val_sampler))]\n",
    "print(df_valid.target.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    valid_ds,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    sampler=val_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ToxicBot(\n",
    "    checkpoint_dir=Path(\"/tmp/\"),\n",
    "    log_dir=Path(\"/tmp/\"),\n",
    "    model=model, train_loader=None,\n",
    "    val_loader=None, optimizer=None,\n",
    "    echo=False,\n",
    "    criterion=None,\n",
    "    avg_window=100,\n",
    "    callbacks=[],\n",
    "    pbar=False,\n",
    "    use_tensorboard=False,\n",
    "    device=DEVICE\n",
    ")\n",
    "valid_pred, valid_y = bot.predict(valid_loader, return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
      "7    0.9621    0.9016                          white        0.8591   \n",
      "5    0.9593    0.9054                         muslim        0.8613   \n",
      "2    0.9742    0.8827      homosexual_gay_or_lesbian        0.8890   \n",
      "6    0.9754    0.8874                          black        0.9051   \n",
      "0    0.9579    0.9550                           male        0.9348   \n",
      "1    0.9634    0.9517                         female        0.9389   \n",
      "4    0.9739    0.9355                         jewish        0.9460   \n",
      "8    0.9839    0.9218  psychiatric_or_mental_illness        0.9470   \n",
      "3    0.9552    0.9674                      christian        0.9511   \n",
      "\n",
      "   subgroup_size  \n",
      "7            452  \n",
      "5            345  \n",
      "2            217  \n",
      "6            276  \n",
      "0            754  \n",
      "1            946  \n",
      "4            142  \n",
      "8             88  \n",
      "3            699  \n",
      "Overall AUC: 0.970701\n",
      "Mean bnsp_auc: 0.966989\n",
      "Mean bpsn_auc: 0.920417\n",
      "Mean subgroup auc: 0.910494\n",
      "Final score: 0.942150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.9421502044674531, '94.22')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('precision', 4)\n",
    "metric = ToxicMetric(df_valid)\n",
    "metric(valid_y, valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
